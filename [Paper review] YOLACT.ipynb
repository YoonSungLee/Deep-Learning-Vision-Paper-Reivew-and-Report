{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time Instance Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper(2019.04) https://arxiv.org/abs/1904.02689<br>\n",
    "github https://github.com/dbolya/yolact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 모델은 MSCOCO dataset 기준으로 29.8mAP, 33.5 fps의 성능을 보였고, 이는 GPU 1대만 가지고 training 한 결과라고 언급한다. 통상적으로 1초에 30fps 정도의 성능을 real-time 이라고 칭한다고 알고 있기 때문에, 해당 모델은 결과를 통해 real-time을 입증한다.<br>\n",
    "<br>\n",
    "**\"We accomplish this by breaking instance segmentation into two parallel substacks.\"**<br>\n",
    "해당 모델은 instance segmentation을 두 개의 병렬 구조의 업무로 나누어 이를 달성한다. 이 두 개의 업무가 무엇인지를 중점적으로 볼 필요가 있다. 업무는 다음과 같다.<br>\n",
    "(1) generating a set of prototype masks<br>\n",
    "(2) predicting per-instance mask coefficients<br>\n",
    "<br>\n",
    "**\"We find that because this process doesn't depend on repooling, this approach produces very high-quality masks and exhibits temporal stability for free.\"**<br>\n",
    "특히 해당 모델은 repooling 에 의존하지 않는 프로세스 때문에 성능이 좋아졌다고 언급한다. repooling 이 무엇인지는 논문을 좀 더 읽거나 검색함으로써 이해할 필요성을 느낀다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/YOLACT01.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"In this work, our goal is to fill that gap with\n",
    "a fast, one-stage instance segmentation model in the same\n",
    "way that SSD and YOLO fill that gap for object detection.\"**<br>\n",
    "Object Detection 분야에는 크게 R-CNN 계열의 모델과 YOLO 계열의 모델이 존재한다. 이렇게 나눈 이유는 모델의 작동방식 때문이다. R-CNN 계열의 모델은 two-stage 방식으로써 정확도는 높지만 속도가 느리다는 단점이 있다. 이와는 반대로 YOLO 계열의 모델은 one-stage 방식으로써 속도가 빠르지만 정확도가 낮다는 단점이 있다. 나의 부족한 소견을 언급하자면, 획기적인 아이디어나 컴퓨팅 성능이 더 발전한다면 이후의 YOLO 계열의 모델이 SOTA 가 되지 않을까 생각한다. 저자 또한 이를 언급하고 있는데, one-stage 모델을 바탕으로 성능이 좋고 속도도 빠른 Instance Segmentation 모델을 만드는 것을 목표로 하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"State-of-the-art two-stage instance segmentation methods depend heavily on feature localization to produce masks. That is, these methods 'repool' features in some bounding box region(e.g., via RoI-pool/align), and then feed these now localized features to their mask predictor.\"**<br>\n",
    "먼저 현재 instance segmentation 분야의 two-stage SOTA 모델의 문제점을 지적한다. two-stage 모델 중의 하나인 Mask R-CNN을 예로 들면, 물체의 BBox를 생성하는 부분과 BBox 내의 물체를 segmentation 하는 부분으로 나누어져 있는데 이를 해당 눈문에서는 'repool'이라고 명명한다. 이전 stage의 feature map을 사용해서 이후 stage를 진행하기 때문이라고 생각한다. 어쨌든 이러한 접근은 일련의 방식을 통해서만 구현이 가능하고, 따라서 속도를 높이기엔 부족하다는 지적을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLACT는 이러한 문제를 one-stage 로 어떻게 해결했는지 살펴보는 것이 핵심이다. 해당 논문은 아래와 같은 설명을 통해 YOLACT의 접근 방법을 소개한다.<br>\n",
    "<br>\n",
    "**\"Instead, YOLACT breaks up instance segmentation into two parallel tasks:<br>\n",
    "(1) generating a dictionary of non-local prototype masks over the entire image, and<br>\n",
    "(2) predicting a set of linear combination coefficients per instance.**<br>\n",
    "바로 머릿속으로 이해되지는 않는 내용이라 뉘앙스만 파악하고 넘어가도록 하자. 전체 이미지에 대하여 여러 개의 prototype mask를 생성하고, instance 마다 선형 결합을 위한 계수들을 예측한다. 이후 각 인스턴스에 대하여 예측된 계수들을 바탕으로 prototype의 선형 결합을 수행하여 segmentation 을 수행한다. 이 정도만 파악하고 다음으로 넘어가겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 방법을 사용한 해당 모델은 여러 장점을 가지고 있다.<br>\n",
    "<br>\n",
    "**\"First and foremost, it's fast\"**<br>\n",
    "two-stage 가 아닌 one-stage 의 병렬 구조이기 때문에 빠른 속도를 자랑한다. 특히 mask branch 에서 굉장히 적은 시간만을 필요로 한다는 것을 알 수 있다.<br>\n",
    "<br>\n",
    "**\"Second, masks are high-quality\"**<br>\n",
    "기존 two-stage 모델들과는 달리 repooling 을 하지 않고 이미지의 전체 공간을 사용하여 mask 를 생성하기 때문에 질이 좋다고 할 수 있다.<br>\n",
    "<br>\n",
    "**\"Finally, it's general\"**<br>\n",
    "해당 모델의 prototype 과 mask coefficients 를 만드는 방법은 다른 object detector 모델에서도 충분히 사용할 수 있다고 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현존하는 Instace Segmentation 은 real-time 을 구현하는데에 있어서 문제가 많다는 내용이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/YOLACT02.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* YOLACT ~ review\n",
    "* read bottom reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLACT\n",
    "* https://arxiv.org/abs/1904.0268\n",
    "\n",
    "(논문리뷰&재구현) YOLACT 설명 및 정리 - (1)\n",
    "* https://ganghee-lee.tistory.com/42\n",
    "\n",
    "(논문리뷰&재구현) YOLACT 설명 및 정리 - (2)\n",
    "* https://ganghee-lee.tistory.com/45\n",
    "\n",
    "(논문리뷰&재구현) YOLACT 설명 및 정리 - (3)\n",
    "* https://ganghee-lee.tistory.com/46\n",
    "\n",
    "(논문리뷰&재구현) YOLACT 설명 및 정리 - (4)\n",
    "* https://ganghee-lee.tistory.com/48"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
